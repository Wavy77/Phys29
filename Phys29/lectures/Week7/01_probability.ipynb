{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability and Statistics\n",
    "\n",
    "Probability distributions and statistical arguments are of fundamental importance in all branches of physics. Examples include: \n",
    "- **Statistical Mechanics** probability distributions are used to conceptualize and describe the aggregate behavior of large numbers of particles (molecules in a gas) where it would it be impractical to track the behavior of each individual particle.  \n",
    "\n",
    "- **Quantum Mechanics** probability distributions describe the likelihood of finding a particle in a particular state.\n",
    "\n",
    "- **Astrophysics** All structure in the universe is the result of the interplay between gravity and the initial conditions of the universe. The Universe's large scale structure and its initial conditions are described with probability distributions. Statistical methods are used to measure, analyze, and interpret the distribution of matter in the Universe.\n",
    "\n",
    "- **Particle Physics** Experiments involving particle collisions use statistical methods to interpret and analyze data. Probability is crucial in the identification of particles and the verification of new particle discoveries.\n",
    "\n",
    "- **Nuclear Physics** Nuclear reactions and decay processes are described using probability distributions.\n",
    "\n",
    "- **Condensed Matter Physics** Statistical methods are used to describe the behavior of large numbers of particles in a solid or liquid.\n",
    "\n",
    "- **Experimental Physics and Observational Astronomy** Statistical methods are used to analyze data from experiments/observations, determine whether physical models are consistent with such data, and to determine the significance of experimental/observational results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last homework you analyzed household income data from the [American Community Survey](https://www.census.gov/programs-surveys/acs) (ACS) conducted by the United States Census Bureau. Using this data we constructed and plotted histograms of household income, as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from census_utils import plot_census_data, generate_fake_census_data\n",
    "plot_census_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram above shows the distribution of household income in the United States in 2022. The data is binned into bins of width $\\Delta I = \\$10,000$ from $\\$0$ to $\\$300,000$, and the histogram indicates the percentage of households in each bin. To make the high-income *tail* of this distribution easier to visualize, I've chosen the last two bins to be wider: the second to last bin is from $\\$300,000$ to $\\$350,000$, and the last bin includes all incomes larger than $\\$350,000$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data for this histogram is a list of incomes, $i_j$ for the $N_{\\rm tot} = 127,970,381$ households in the United States (with income $> 0$), where $j=1,2,3,..., N_{\\rm tot}$ (the average size of a US household is 2.3 people, according to this dataset).   Here $i_j$ is a continuous variable that can take on any value, whereas the centers of the histogram bins, which we will denote as $I_k$, are discrete. \n",
    "\n",
    "Let's  compute the histogram  over the full range of the data (i.e. without the two wider bins at the end) and use it to frame our discussion of proability distributions. You know from the homework that the real data was not a list of incomes for all $127,970,381$ housholds in the United States, but rather a shorter list of records with weights that indicate the number of households that each record represents. For the purposes of the discussion here, I've \n",
    "written code to generate a fake list of $N_{\\rm tot}= 1,000,000$ incomes (without the weights) drawn from the distribution of the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "incomes = generate_fake_census_data()\n",
    "N_tot = len(incomes)\n",
    "print(N_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# Construct the bins\n",
    "bin_width = 10000\n",
    "# Maximum value is 2,481,200, so go up to 2.5 million\n",
    "I_edges = np.arange(0, 2500000, bin_width)\n",
    "\n",
    "# Compute the histogram using numpy\n",
    "N_of_I, _ = np.histogram(incomes, bins=I_edges)\n",
    "I_centers = (I_edges[1:] + I_edges[:-1])/2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.bar(I_edges[:-1], N_of_I, width=np.diff(I_edges), align='edge', color='orange', \n",
    "       alpha=1.0, edgecolor='black', zorder=10, label='Census data')\n",
    "plt.xlabel('I (income)', fontsize=16)\n",
    "plt.ylabel('N(I) (number per bin)', fontsize=16)\n",
    "plt.legend()\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each histogram bin $k$ contains the number of households, $N(I_k)$, with income $i_j$ in the range $I_k - \\Delta I/2 \\leq i_j < I_k + \\Delta I/2$, where $I_k$ is the center of the bin. The total number of households is then\n",
    "<a id='eqn:N_tot'></a>\n",
    "$$\n",
    "N_{\\rm tot} = \\sum_{k=0}^{N_{\\rm bins}-1} N(I_k) \\tag{1},\n",
    "$$\n",
    "where $N_{\\rm bins}$ is the number of bins in the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check that our histogram includes all the data\n",
    "assert np.sum(N_of_I) == N_tot  # an assertion error will be raised if the condition is not met\n",
    "print('N_tot:', N_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean, Variance, and Mode\n",
    "\n",
    "The mean income $\\langle i \\rangle$ is the average income over all households, \n",
    "$$\n",
    "\\langle i \\rangle = \\frac{1}{N_{\\rm tot}} \\sum_{j=0}^{N_{\\rm tot-1}} i_j \\approx \\frac{1}{N_{\\rm tot}} \\sum_{k=0}^{N_{\\rm bins}-1} I_k N(I_k) = \\langle I\\rangle,\n",
    "$$\n",
    "where the second equality is an approximation since $i_j$ is a continuous quantity, whereas the $I_k$ are discrete. In the limit that $\\Delta I \\rightarrow 0$, the approximation becomes exact and $\\langle i \\rangle = \\langle I\\rangle$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two ways to compute the mean\n",
    "i_bar = np.sum(incomes)/N_tot # see also np.mean(incomes)\n",
    "I_bar = np.sum(N_of_I*I_centers)/N_tot\n",
    "print(f'<i> = ${i_bar:.2f} ; <I> = ${I_bar:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the relative frequency (probability) of a household having a given income $I_k$ as\n",
    "$$\n",
    "P(I_k) = \\frac{N(I_k)}{N_{\\rm tot}}. \n",
    "$$\n",
    "Note that the probability distribution or distribution function, $P(I_k)$, satisfies the **normalization condition**\n",
    "$$\n",
    "\\sum_{k=0}^{N_{\\rm bins}-1} P(I_k) = \\frac{1}{N_{\\rm tot}} \\sum_{k=0}^{N_{\\rm bins}-1} N(I_k) = 1, \n",
    "$$\n",
    "where we have used eqn.(<a href=\"#eqn:N_tot\">1</a>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_of_I = N_of_I/N_tot\n",
    "assert np.isclose(np.sum(P_of_I), 1.0)\n",
    "print(f'The sum of the probabilities is: {np.sum(P_of_I)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in terms of $P(I_k)$, the mean income is\n",
    "$$\n",
    "\\langle I\\rangle = \\sum_{k=0}^{N_{\\rm bins}-1} I_k P(I_k).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the mean-square income, $\\langle i^2\\rangle$, which is the average of the square of the income over all households,\n",
    "$$\n",
    "\\langle i^2\\rangle = \\frac{1}{N_{\\rm tot}}\\sum_{j=0}^{N_{\\rm tot}-1} i_j^2 \\approx \\sum_{k=0}^{N_{\\rm bins}-1} I_k^2 P(I_k) = \\langle I^2\\rangle,\n",
    "$$\n",
    "or taking the square-root, we obtain the **root-mean-square** (RMS) income,\n",
    "$$\n",
    "I_{\\rm rms} = \\sqrt{\\langle I^2\\rangle}.\n",
    "$$\n",
    "\n",
    "A related useful quantity is the **variance** of the income distribution, which is a measure of the spread of the distribution. The variance is defined as\n",
    "$$\n",
    "\\sigma_i^2 \\equiv \\langle (i - \\langle i\\rangle)^2\\rangle \\approx  \\langle (I - \\langle I\\rangle)^2\\rangle \\equiv \\sigma_I^2 = \\sum_{k=0}^{N_{\\rm bins}-1} (I_k - \\langle I\\rangle)^2 P(I_k), \n",
    "$$\n",
    "where again the approximation arises because $i_j$ is continuous and $I_k$ is discrete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by expanding the square in the definition of the variance, we can write\n",
    "$$\n",
    "\\begin{align*}\n",
    "{\\rm Var}(i) = \\sigma_i^2 & \\approx \\sigma_I^2 = \\sum_{k=0}^{N_{\\rm bins}-1} (I_k^2 - 2 \\langle I\\rangle I_k + \\langle I\\rangle^2) P(I_k)\\\\\n",
    "         &  = \\sum_{k=0}^{N_{\\rm bins}-1} I_k^2 P(I_k) - 2 \\langle I\\rangle \\sum_{k=0}^{N_{\\rm bins}-1} I_k P(I_k) + \\langle I\\rangle^2 \\sum_{k=0}^{N_{\\rm bins}-1} P(I_k)\\\\\n",
    "        & = \\langle I^2\\rangle - 2\\langle I\\rangle^2 + \\langle I\\rangle^2\\\\\n",
    "        &  = \\langle I^2\\rangle - \\langle I\\rangle^2.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **standard deviation** is the square root of the variance, \n",
    "$$\n",
    "\\sigma_I = \\sqrt{\\sigma_I^2} = \\sqrt{\\langle I^2\\rangle - \\langle I\\rangle^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the probability distribution P_of_I\n",
    "P_of_I = (N_of_I/N_tot)\n",
    "# Two ways to compute the standard deviation \n",
    "sigma_i = np.std(incomes) # from the original data\n",
    "sigma_i_2 = np.sqrt(np.mean((incomes - i_bar)**2)) # from the original data\n",
    "var_i = sigma_i**2\n",
    "sigma_I = np.sqrt(np.sum(P_of_I*(I_centers - I_bar)**2)) # from the histogram\n",
    "assert np.isclose(sigma_i, sigma_i_2)\n",
    "print(f'sigma_i = ${sigma_i:.2f} ; sigma_I = ${sigma_I:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful quantity for characterizing probability distributions is the **mode**\n",
    "$$\n",
    "I_{\\rm mode} = \\max_k P(I_k),\n",
    "$$\n",
    "which is the value of $I_k$ at which the probability distribution is maximized.  This is the most probable value of the income if you randomly draw households from the US population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mode\n",
    "print(np.max(P_of_I))\n",
    "k_max = np.argmax(P_of_I)\n",
    "print(k_max)\n",
    "I_mode = I_centers[k_max]\n",
    "print(f'The mode of the distribution is: ${I_mode:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative Distribution Function and Median\n",
    "\n",
    "Another very important quantity is the **cumulative distribution function** (CDF), which is defined by \n",
    "$$\n",
    "{\\rm CDF}(\\le I_k) = \\sum_{k^\\prime=0}^{k} P(I_{k^\\prime}). \n",
    "$$\n",
    "Since it sums over all $P(I_k)$ for $k^\\prime \\le k$, the CDF is a measure of the probability that a household has an income less than or equal to $I_k$. For example, for the household income data, if the probability that a household has an income less than or equal to \\$128,000 is 75% then ${\\rm CDF}(\\le \\$128,000) = 0.75$. In code, we can compute the CDF using\n",
    "the `np.cumsum` function in `numpy` as we will show below. \n",
    "\n",
    "The **median** is the value of $I_k$ encompassing 50% of the cumulative probability. It is defined by the equation\n",
    "$$\n",
    "\\sum_{k=0}^{k_{\\rm med}} P(I_k) = 0.5 \\quad ; \\quad I_{\\rm k_{\\rm med}} \\equiv \\text{the median income}. \n",
    "$$\n",
    "If we return to the continuous variable $i_j$, the median income is the value of $i_j$ such that 50% of the households have an income less than or equal to this value, which is just the *midpoint* of the list of $i_j$ values when they are sorted in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "# Two ways to compute the median\n",
    "i_median = np.median(incomes) # First way, from the original data\n",
    "# Second way, from histogram find the bin that contains 50% of the cumulative probability\n",
    "P_cumulative = np.cumsum(P_of_I) \n",
    "# Cumsum means P_cumulative[0] = P_of_I[0]; P_cumulative[1] = P_of_I[0] + P_of_I[1], etc.\n",
    "# Find the first bin where the cumulative probability exceeds 0.5\n",
    "k_med = np.argmax(P_cumulative > 0.5) \n",
    "# np.argmax finds the index of the maximum value in a numpy array. For a Boolean array, the\n",
    "# maximum value is True, and np.argmax defaults to return the first element at which the max \n",
    "# is achieved, which is here the first element of the array where the condition is true\n",
    "I_median = I_centers[k_med]\n",
    "plt.plot(I_centers, P_cumulative, 'k-')\n",
    "plt.xlabel('I (income in $)', fontsize=16)\n",
    "plt.ylabel(r'$CDF(\\leq I)$ (cumulative probability)', fontsize=16)\n",
    "plt.axhline(0.5, color='red', linestyle='--')\n",
    "plt.plot([i_median, i_median],[0.0, 0.5], color='red', linestyle='--')\n",
    "# Set the major tick mark spacing on the y-axis to 0.1\n",
    "plt.gca().yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "print(f'i_median = ${i_median:.2f} ; I_median = ${I_median:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the mean and median of the US household income distribution are not the same: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The mean=${i_bar:.2f}, whereas the median=${i_median:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for this is that the distribution posseses a large tail of high-income households, which pulls the mean towards higher values relative to the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Versus Continuous Probability Distributions\n",
    "\n",
    "In some applications the variable of interest is discrete, for example if we are considering rolling a die, there are six discrete possible outcomes: 1, 2, 3, 4, 5, or 6, but a value of 1.5 is impossible. So the probability distribution would similarly have six \n",
    "discrete values, $P(1)$, $P(2)$, $P(3)$, $P(4)$, $P(5)$, and $P(6)$.\n",
    "\n",
    "In other cases the variable is continuous, for example household incomes, $i_j$, can take on any real number in the range $0 \\leq i_j < \\infty$. In the example above however, we were dealing with a dataset with a finite number of entires. To visualize the probability distribution of a continuous variable for a finite dataset, we use a histogram, $P(I_k)$, with a finite number of discrete bins. \n",
    "\n",
    "Now consider the case of a continuous distribution of some variable $x$. We define $P(x)$ by\n",
    "$$\n",
    "N(x) = N_{\\rm tot} P(x) \\Delta x \\quad ; \\quad N(x)\\propto \\Delta x,  \n",
    "$$\n",
    "where $N(x)$ is the number of events in the range $x$ to $x+\\Delta x$. Clearly in the limit $\\Delta x \\rightarrow 0$ and $N_{\\rm tot} \\rightarrow \\infty$,  $P(x)$ goes from being a histogram to a continuous function \n",
    "$$\n",
    "P(x) = \\lim_{\\substack{\\Delta x \\to 0 \\\\ N_{\\rm tot} \\to \\infty}} \\frac{N(x)}{N_{\\rm tot} \\Delta x}. \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For continuous probability distributions, the discrete sums then become integrals, i.e. \n",
    "$$\n",
    "\\int P(x) dx = 1, \\quad \\quad \\text{normalization condition}.\n",
    "$$\n",
    "Note that $P(x)$ is a **probability density** and now has units of $[1/x]$, i.e. $P(x)dx$ is the infinitesimal dimensionless probability of finding $x$ in the range $x$ to $x+dx$.\n",
    "\n",
    "The mean is now defined by\n",
    "<a id='eqn:mean'></a>\n",
    "$$\n",
    "\\langle x\\rangle = \\int x P(x) dx, \\quad \\quad \\text{mean}, \\tag{2}\n",
    "$$\n",
    "and likewise the variance is\n",
    "<a id='eqn:variance'></a>\n",
    "$$\n",
    "{\\rm Var}(x) = \\sigma^2 = \\int (x - \\langle x\\rangle)^2 P(x) dx, \\quad \\quad \\text{variance}. \\tag{3}\n",
    "$$\n",
    "\n",
    "For a continuous variable defined on the entire  real line, $x \\in (-\\infty, \\infty)$, the CDF then becomes\n",
    "$$\n",
    "{\\rm CDF}(\\le x) = \\int_{-\\infty}^x P(x^\\prime) dx^\\prime,\n",
    "$$\n",
    "where again ${\\rm CDF}(\\le x)$ is the probability of encountering a value that is less than or equal to $x$.  \n",
    "\n",
    "The median of the distribution then becomes\n",
    "$$\n",
    "{\\rm CDF}(\\le x_{\\rm med}) = 0.5 \\quad ; \\quad x_{\\rm med} \\equiv \\text{the median value}.\n",
    "$$\n",
    "for the continous case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Distributions of Multiple Variables and Statistical Independence\n",
    "\n",
    "In many cases that arise we are interested in the probability distribution of multiple random variables. For example, in the case of the American Community Survey, we might be interested in the **joint probability distribution** of household income and the number of people in the household $P(I,N)$. \n",
    "\n",
    "A related concept to a probability distribution of multiple variables, is a **conditional probability** distribution. The conditional probability is the probability that something occurs given that we know something else has occurred. For example, if we imagine holding the household size fixed at a specific value of $N$ (say $N=1$ person), what is the probability distribution of, $I$, the income for these one person households. You can imagine mapping this conditional income distribution out at each value of $N$. Mathematically, we write this as the conditional probability distribution $P(I|N)$, which is read as *the probability of $I$ given $N$*. \n",
    "\n",
    "In general, the joint probability distribution of two variables, $x$ and $y$, is related to the conditional probability by\n",
    "<a id='eqn:P(x|y)'></a>\n",
    "$$\n",
    "P(x,y) = P(x|y)P(y), \\tag{4} \n",
    "$$\n",
    "which makes intuitive sense: the probability of $x$ and $y$ occurring together is the probability of $x$ occurring given that $y$ has occurred, times the probability of $y$ occurring on its own. Of course we could also think about it the opposite way, i.e.\n",
    "<a id='eqn:P(y|x)'></a>\n",
    "$$\n",
    "P(x,y) = P(y|x)P(x), \\tag{5}\n",
    "$$\n",
    "which says: the probability of $x$ and $y$ occurring together is the probability of $y$ occurring given that $x$ has occurred, times the probability of $x$ occurring on its own. \n",
    "\n",
    "The two variables $x$ and $y$ are **statistically independent** if the probability distribution of $x$ is not affected by the value of $y$, and vice versa, i.e. \n",
    "$$\n",
    "P(x|y) = P(x) \\quad \\text{and} \\quad P(y|x) = P(y).\n",
    "$$\n",
    "Plugging either of these equations into eqns.(<a href=\"#eqn:P(x|y)\">4</a>) or (<a href=\"#eqn:P(y|x)\">5</a>) we see that the joint probability distribution of $x$ and $y$ is the product of the individual probability distributions of $x$ and $y$, i.e.\n",
    "<a id='eqn:joint'></a>\n",
    "$$\n",
    "P(x,y) = P(x)P(y). \\tag{6}\n",
    "$$\n",
    "Again this makes intuitive sense. If we have two independent dice, the probability of rolling a 3 on one die is not affected by the value of the other die, and vice versa.  Hence the probability of rolling a 3 on both dice is the product of the probability of rolling a 3 on each die individually.\n",
    "\n",
    "Finally, because of the symmetry of  eqns.(<a href=\"#eqn:P(x|y)\">4</a>) or (<a href=\"#eqn:P(y|x)\">5</a>), we can equate them to arrive at one of the most important results in probability theory, **Bayes' Theorem**:\n",
    "$$\n",
    "P(x,y) =  P(x|y)P(y) = P(y|x)P(x) \\quad \\rightarrow \\quad P(x|y) = \\frac{P(y|x)P(x)}{P(y)}, \n",
    "$$\n",
    "which forms the foundation of **Bayesian statistics**. We will use Bayes' theorem in a future lecture when we discuss fitting models to data, also known as statistical inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of the Mean and Variance Operators\n",
    "The mean and variance over the probability distribution governing a random process are **operators** that instruct us to perform a specific mathematical operation. For example, consider a single continuous random variable $x$ governed by a probability distribution $P(x)$. For an arbitrary function $f(x)$, the mean over\n",
    "the distribution is \n",
    "$$\n",
    "\\langle f(x) \\rangle = \\int f(x) P(x) dx, \\quad \\quad \\text{mean; single variable $x$}. \n",
    "$$\n",
    "and the variance is\n",
    "$$\n",
    "{\\rm Var}[f(x)] = \\int \\left[f(x) - \\langle f(x)\\rangle\\right]^2 P(x)dx, \\quad \\quad \\text{variance; single variable $x$}.\n",
    "$$\n",
    "Similarly, for two random variables $x$ and $y$ governed by a joint probability distribution, $P(x,y)$, the mean of the function $f(x,y)$ would be\n",
    "$$\n",
    "\\langle f(x,y) \\rangle = \\int f(x,y) P(x,y)dxdy, \\quad \\quad \\text{mean; two variables $x$ and $y$},\n",
    "$$\n",
    "and  the variance is\n",
    "$$\n",
    "{\\rm Var}[f(x,y)] = \\int \\left[f(x,y) - \\langle f(x,y)\\rangle\\right]^2 P(x,y)dxdy, \\quad \\quad \\text{variance; two variables $x$ and $y$}. \n",
    "$$\n",
    "\n",
    "\n",
    "Later we will exploit the fact that these operators satisfy certain properties, *independent of the functional form of the probability distribution*.  For example if $A$ is a constant that does not depend on the random variable(s), then \n",
    "$$ \n",
    "\\langle A \\rangle = A \\quad \\text{and} \\quad {\\rm Var}(A) = 0, \n",
    "$$\n",
    "which you can easily prove by using the definitions above.\n",
    "\n",
    "Additionally, \n",
    "$$\n",
    "\\langle A x \\rangle = A \\langle x \\rangle \\quad \\quad \\text{and} \\quad \\quad {\\rm Var}(A x) = A^2 {\\rm Var}(x).   \n",
    "$$\n",
    "The mean is a **linear operator**, so for the two random variables $x$ and $y$, and constants $A$ and $B$, we have\n",
    "$$\n",
    "\\langle Ax + By \\rangle = A\\langle x \\rangle + B\\langle y \\rangle\n",
    "$$\n",
    "\n",
    "Finally, if $x$ and $y$ are **statistically independent** random variables, i.e. $P(x,y) = P(x)P(y)$, and $A$ and $B$ are constants, then it follows that\n",
    "$$\n",
    " {\\rm Var}(Ax + By) = A^2{\\rm Var}(x) + B^2{\\rm Var}(y), \n",
    "$$\n",
    "where \n",
    "$$\n",
    "\\langle x \\rangle = \\int x P(x) dx, \\quad \\quad \\text{and} \\quad \\quad {\\rm Var}(x) = \\int (x-\\langle x\\rangle)^2 P(x) dx. \n",
    "$$\n",
    "and likewise for $y$.\n",
    "\n",
    "You will prove these properties in the homework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Phys29",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
